{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://github.com/marcotcr/checklist/blob/master/notebooks/tutorials/3.%20Test%20types,%20expectation%20functions,%20running%20tests.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = ['This was a very nice movie directed by John Smith.',\n",
    "           'Mary Keen was brilliant.', \n",
    "          'I hated everything about this.',\n",
    "          'This movie was very bad.',\n",
    "          'I really liked this movie.',\n",
    "          'just bad.',\n",
    "          'amazing.',\n",
    "          ]\n",
    "pdataset = list(nlp.pipe(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invariance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was a very nice movie directed by John Smith.\n",
      "This was a very nice movie directed byJ ohn Smith.\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# t = Perturb.perturb(pdataset, Perturb.change_names)\n",
    "\n",
    "t = Perturb.perturb(dataset, Perturb.add_typos)\n",
    "print('\\n'.join(t.data[0][:3]))\n",
    "print('...')\n",
    "test = INV(**t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "def predict_proba(inputs):\n",
    "    p1 = np.array([(sentiment(x)[0] + 1)/2. for x in inputs]).reshape(-1, 1)\n",
    "    p0 = 1- p1\n",
    "    return np.hstack((p0, p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15, 0.85],\n",
       "       [0.85, 0.15]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions are random\n",
    "predict_proba(['good', 'bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "wrapped_pp = PredictorWrapper.wrap_softmax(predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 14 examples\n",
      "Test cases:      7\n",
      "Fails (rate):    2 (28.6%)\n",
      "\n",
      "Example fails:\n",
      "0.9 Mary Keen was brilliant.\n",
      "0.5 Mary Keen was brillinat.\n",
      "\n",
      "----\n",
      "0.8 amazing.\n",
      "0.5 maazing.\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "test.run(wrapped_pp)\n",
    "test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455ec1d2c2e44d1d9d01e31f17936884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TestSummarizer(stats={'npassed': 5, 'nfailed': 2, 'nfiltered': 0}, summarizer={'name': None, 'description': No…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.visual_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_negative(x):\n",
    "    phrases = ['Anyway, I thought it was bad.', 'Having said this, I hated it', 'The director should be fired.']\n",
    "    return ['%s %s' % (x, p) for p in phrases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('This was a very nice movie directed by John Smith.',\n",
       " ['This was a very nice movie directed by John Smith. Anyway, I thought it was bad.',\n",
       "  'This was a very nice movie directed by John Smith. Having said this, I hated it',\n",
       "  'This was a very nice movie directed by John Smith. The director should be fired.'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0], add_negative(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.expect import Expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonic_decreasing = Expect.monotonic(label=1, increasing=False, tolerance=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Perturb.perturb(dataset, add_negative)\n",
    "test = DIR(**t, expect=monotonic_decreasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 28 examples\n",
      "Test cases:      7\n",
      "After filtering: 6 (85.7%)\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "test.run(wrapped_pp)\n",
    "test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d397a65c334d6ebdb765b3e1cf3bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TestSummarizer(stats={'npassed': 6, 'nfailed': 0, 'nfiltered': 0}, summarizer={'name': None, 'description': No…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.visual_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
